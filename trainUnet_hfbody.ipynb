{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jy_2-BghSVce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpsQS266SQcS"
   },
   "source": [
    "## Train your Unet with medical data\n",
    "it is a binary classification task.\n",
    "\n",
    "The input shape of image and mask are the same :(batch_size,rows,cols,channel = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HiMahBZNSQcT"
   },
   "source": [
    "### Set hyperparameters\n",
    "\n",
    "* epochs_no - more runs and improvs generalisation of the model\n",
    "* batch_size - number of samples to run at each epoch step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parametrs\n",
    "batch_size = 8\n",
    "epochs_no = 2000\n",
    "steps_per_epoch = epochs_no / batch_size\n",
    "epochs_no = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 1024) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 1)  3           conv2d_23[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,031,685\n",
      "Trainable params: 31,031,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Research\\ML\\unet_ml\\model.py:55: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input = inputs, output = conv10)\n"
     ]
    }
   ],
   "source": [
    "input_size = (256,256,1) # actual data\n",
    "#input_size = (256,256,1) # Augmented data\n",
    "model = unet(input_size=input_size)\n",
    "# Monitor can be either acc or val_loss or val_acc\n",
    "model_checkpoint = ModelCheckpoint('unet_halfbody.hdf5', monitor='loss',verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack Over Flow discussion - https://stackoverflow.com/questions/47930176/printing-out-the-validation-accuracy-to-the-console-for-every-batch-or-epoch-ke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2550
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9929571,
     "status": "error",
     "timestamp": 1557936099610,
     "user": {
      "displayName": "Polycarp Omondi Okock",
      "photoUrl": "https://lh6.googleusercontent.com/-EU3oIny4yXk/AAAAAAAAAAI/AAAAAAAAIAU/RmdKW9Vydf0/s64/photo.jpg",
      "userId": "13920548887298274898"
     },
     "user_tz": -60
    },
    "id": "et43jcK1SQcU",
    "outputId": "d631b7e6-7aa6-4e59-8ccc-fb367eaca8bf"
   },
   "outputs": [],
   "source": [
    "#if you don't want to do data augmentation, set data_gen_args as an empty dict.\n",
    "#data_gen_args = dict()\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2550
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9929571,
     "status": "error",
     "timestamp": 1557936099610,
     "user": {
      "displayName": "Polycarp Omondi Okock",
      "photoUrl": "https://lh6.googleusercontent.com/-EU3oIny4yXk/AAAAAAAAAAI/AAAAAAAAIAU/RmdKW9Vydf0/s64/photo.jpg",
      "userId": "13920548887298274898"
     },
     "user_tz": -60
    },
    "id": "et43jcK1SQcU",
    "outputId": "d631b7e6-7aa6-4e59-8ccc-fb367eaca8bf"
   },
   "outputs": [],
   "source": [
    "# Actual data size ~train, label folders and uses augmented saved data in ~aug folder\n",
    "trainGene = trainGenerator(batch_size,'data/halfbody/train','image','label',data_gen_args,save_to_dir = None)\n",
    "\n",
    "# Downsampled data and no augmentation\n",
    "#myGene = trainGenerator(batch_size,'data/halfbody/train','image_downsampled','label_downsampled',data_gen_args,save_to_dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "testGene = trainGenerator(batch_size,'data/halfbody/train','test_image','test_label',data_gen_args,save_to_dir = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fit Generator\n",
    "\n",
    "* https://keras.io/models/model/\n",
    "* https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2550
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9929571,
     "status": "error",
     "timestamp": 1557936099610,
     "user": {
      "displayName": "Polycarp Omondi Okock",
      "photoUrl": "https://lh6.googleusercontent.com/-EU3oIny4yXk/AAAAAAAAAAI/AAAAAAAAIAU/RmdKW9Vydf0/s64/photo.jpg",
      "userId": "13920548887298274898"
     },
     "user_tz": -60
    },
    "id": "et43jcK1SQcU",
    "outputId": "d631b7e6-7aa6-4e59-8ccc-fb367eaca8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Found 770 images belonging to 1 classes.\n",
      "Found 1259 images belonging to 1 classes.\n",
      "Found 770 images belonging to 1 classes.\n",
      "Found 1259 images belonging to 1 classes.\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.3483 - acc: 0.9772 - val_loss: 0.2750 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.34846, saving model to unet_halfbody.hdf5\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 260s 1s/step - loss: 0.3353 - acc: 0.9792 - val_loss: 0.2746 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00002: loss improved from 0.34846 to 0.33565, saving model to unet_halfbody.hdf5\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 260s 1s/step - loss: 0.3403 - acc: 0.9789 - val_loss: 0.2731 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.33565\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 259s 1s/step - loss: 0.3374 - acc: 0.9791 - val_loss: 0.2748 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.33565\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 259s 1s/step - loss: 0.3357 - acc: 0.9792 - val_loss: 0.2750 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00005: loss improved from 0.33565 to 0.33564, saving model to unet_halfbody.hdf5\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 258s 1s/step - loss: 0.3390 - acc: 0.9790 - val_loss: 0.2746 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.33564\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 262s 1s/step - loss: 0.3349 - acc: 0.9792 - val_loss: 0.2738 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00007: loss improved from 0.33564 to 0.33526, saving model to unet_halfbody.hdf5\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 263s 1s/step - loss: 0.3396 - acc: 0.9789 - val_loss: 0.2746 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.33526\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 263s 1s/step - loss: 0.3398 - acc: 0.9789 - val_loss: 0.2755 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.33526\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 262s 1s/step - loss: 0.3360 - acc: 0.9792 - val_loss: 0.2742 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.33526\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 263s 1s/step - loss: 0.3372 - acc: 0.9791 - val_loss: 0.2725 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.33526\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 263s 1s/step - loss: 0.3404 - acc: 0.9789 - val_loss: 0.2767 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.33526\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 261s 1s/step - loss: 0.3385 - acc: 0.9790 - val_loss: 0.2730 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.33526\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 262s 1s/step - loss: 0.3384 - acc: 0.9790 - val_loss: 0.2754 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.33526\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 261s 1s/step - loss: 0.3347 - acc: 0.9792 - val_loss: 0.2742 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00015: loss improved from 0.33526 to 0.33439, saving model to unet_halfbody.hdf5\n",
      "Epoch 16/200\n",
      "110/250 [============>.................] - ETA: 1:49 - loss: 0.3448 - acc: 0.9786"
     ]
    }
   ],
   "source": [
    "HistDict = model.fit_generator(trainGene,steps_per_epoch=steps_per_epoch,epochs=epochs_no, verbose=1, validation_data = testGene, validation_steps = steps_per_epoch,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the training loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = epochs_no\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), HistDict.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), HistDict.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), HistDict.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), HistDict.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(\"data/halfbody/plot_halfbody.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UzINw3kISQcY"
   },
   "source": [
    "### Train with npy file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Train with Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zrx8y-m5SQcZ"
   },
   "outputs": [],
   "source": [
    "imgs_train,imgs_mask_train = geneTrainNpy(\"data/halfbody/train/aug/\",\"data/halfbody/train/aug/\")\n",
    "#HistDict = model.fit(imgs_train, imgs_mask_train, batch_size=batch_sizes, epochs=epochs_no, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Train with Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train,imgs_mask_train = geneTrainNpy(\"data/halfbody/train/image_downsampled/\",\"data/halfbody/train/label_downsampled/\", image_prefix=\"\",mask_prefix=\"\")\n",
    "model.fit(imgs_train, imgs_mask_train, batch_size=batch_size, epochs=epochs_no, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tabcxlRSQcb"
   },
   "source": [
    "### Test your model and save predicted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXO5tbsVfq4V"
   },
   "source": [
    "Link to Stack overflow discussion - https://stackoverflow.com/questions/52946110/u-net-low-contrast-test-images-predict-output-is-grey-box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the output data dimension here\n",
    "\n",
    "input and target size must match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15130,
     "status": "ok",
     "timestamp": 1557936123394,
     "user": {
      "displayName": "Polycarp Omondi Okock",
      "photoUrl": "https://lh6.googleusercontent.com/-EU3oIny4yXk/AAAAAAAAAAI/AAAAAAAAIAU/RmdKW9Vydf0/s64/photo.jpg",
      "userId": "13920548887298274898"
     },
     "user_tz": -60
    },
    "id": "Dgdwk0rNSQcb",
    "outputId": "8c5bb3dc-b9c8-4231-ca06-d71379af16a9"
   },
   "outputs": [],
   "source": [
    "## Resample to original sizes\n",
    "input_size = (512,512,1)\n",
    "target_size=(512,512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on n datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_path = 'data/halfbody/test_orig'\n",
    "num_images = 0\n",
    "for entry in os.listdir(test_path):\n",
    "    if os.path.isfile(os.path.join(test_path, entry)):\n",
    "        if entry.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            num_images = num_images + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15130,
     "status": "ok",
     "timestamp": 1557936123394,
     "user": {
      "displayName": "Polycarp Omondi Okock",
      "photoUrl": "https://lh6.googleusercontent.com/-EU3oIny4yXk/AAAAAAAAAAI/AAAAAAAAIAU/RmdKW9Vydf0/s64/photo.jpg",
      "userId": "13920548887298274898"
     },
     "user_tz": -60
    },
    "id": "Dgdwk0rNSQcb",
    "outputId": "8c5bb3dc-b9c8-4231-ca06-d71379af16a9"
   },
   "outputs": [],
   "source": [
    "# Path toread datasets tp apply prediction to\n",
    "testGene = testGenerator(test_path, num_image=num_images, target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15130,
     "status": "ok",
     "timestamp": 1557936123394,
     "user": {
      "displayName": "Polycarp Omondi Okock",
      "photoUrl": "https://lh6.googleusercontent.com/-EU3oIny4yXk/AAAAAAAAAAI/AAAAAAAAIAU/RmdKW9Vydf0/s64/photo.jpg",
      "userId": "13920548887298274898"
     },
     "user_tz": -60
    },
    "id": "Dgdwk0rNSQcb",
    "outputId": "8c5bb3dc-b9c8-4231-ca06-d71379af16a9"
   },
   "outputs": [],
   "source": [
    "model = unet(input_size=input_size)\n",
    "model.load_weights(\"unet_halfbody.hdf5\")\n",
    "results = model.predict_generator(testGene,num_images,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15130,
     "status": "ok",
     "timestamp": 1557936123394,
     "user": {
      "displayName": "Polycarp Omondi Okock",
      "photoUrl": "https://lh6.googleusercontent.com/-EU3oIny4yXk/AAAAAAAAAAI/AAAAAAAAIAU/RmdKW9Vydf0/s64/photo.jpg",
      "userId": "13920548887298274898"
     },
     "user_tz": -60
    },
    "id": "Dgdwk0rNSQcb",
    "outputId": "8c5bb3dc-b9c8-4231-ca06-d71379af16a9"
   },
   "outputs": [],
   "source": [
    "# Input is image and path to save the predicted datasets to\n",
    "saveResult(\"data/halfbody/test_orig_label\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainUnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
